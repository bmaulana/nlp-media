5 per article, {Autism, Dementia, Dyslexia}:
vader   Positive: 0.06454444444444446   Neutral: -0.022673333333333334      Negative: 0.030268888888888887
xiaohan         Positive: -0.08651992567032271  Neutral: -0.2223492263472873        Negative: -0.08588073515935767
kcobain         Positive: 0.03888888888888889   Neutral: -0.027777777777777776      Negative: -0.027777777777777776
openai  Positive: 0.1341486997074551    Neutral: 0.04361653866039382        Negative: -0.005045107669300503

Notes:

XiaoHan's and Kevin Cobain's is all over the place. (some neutral ones have very high + or - scores)

OpenAI's misses a lot of negative ones, e.g:
{'keyword_count': 1, 'sentiment_score_vader': 0.0, 'sentiment_score_xiaohan': -0.4151260102910689,
'sentiment_score_kcobain': -0.75, 'sentiment_score_openai': 0.14298953115940094}
Police Tasered autistic man, 25, with mental age of seven.

Also, dementia should be removed. Model works better with classifying representations of 'born-with'/unavoidable disabilities
e.g. Eating a healthy, balanced diet could also lower your risk of dementia, according to the NHS.
(Positive, but if you e.g. replace 'dementia' with 'autism', would be negative)-
Lots of sentences about increasing/redusing risk, occurrence, cases of dementia/Alzheimer's

Main issues with using models trained on movie/product review, e.g:
He reveals that until he was 21 he could not spell his name; and the outstanding moments of this solo come when his da
ncing combines with digital imagery to portray the confusion and alienation his dyslexia caused. + (all)
(+ for a review, neutral/- for an article)

____________________________________

GUIDELINES:
using __ics or 'suffers from' (or other inappropriate terms): negative
(Only) focus on the disability's downsides: negative
Implying <something> causes <disability> (if said disability is a lifelong condition): negative
Helping people with <disability>: positive
Talk about experiences of people with <disability>: positive
Coming out with <disability>: positive

_____________________________________

From analysing sentiment_eval.png:
OpenAI seems to be the best option, score-wise.
Clear distinction between the peaks and distributions of positive, neutral, and negative
Only issues, results-wise, are:
1) that the data seems to be positive-skewed
(negative labels are more prone to false positives of actually neutral articles, or negative articles labelled positive)
2) there's a lot of overlap between the distributions (especially neutral and negative)
The main issue, of course, is the performance - requires 10s-1min to analyse each article.
Not fast enough for tens-of-thousands articles. <2 sec required to
Further optimisation

If OpenAI is unavailable due to performance reasons, the second best would be VADER:
Clear distinction between articles classified as positive (anything >0.0 are mostly manually labelled positive)
and negative (anything <0.0 are mostly manually labelled positive)
Issue is labels too much things as 0.0 and 'misses' the labels on a lot of actually-positive/negative articles.
With this approach, we can use VADER but ignore 0.0 labels for our plotting/analysis

Other measures are flawed, to varying degrees:
Kevin Cobain: Not too bad actually, however there seem to be more false positives/negatives than OpenAI. Also no paper
Also graph may be missing some values above +1.0 or below -1.0, which is possible with this regressor
TextBlob: again not too bad, similar distribution to OpenAI but more overlapping and false negatives. Also no paper
TextBlob-Bayes: Out of the question. Scores seem very random (and scores too much as +1.0)
StanfordNLP: Out of the question. Scores everything as -0.5.
XiaoHan: Out of the question. Scores most articles as -1.0.